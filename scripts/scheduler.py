"""
å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
åŠŸèƒ½ï¼šåœ¨æ¯å¤©çš„9:30ã€15:30ã€20:30è‡ªåŠ¨æ‰§è¡Œåˆ†ææµç¨‹
"""

import os
import sys
import logging
from datetime import datetime
from apscheduler.schedulers.blocking import BlockingScheduler
from apscheduler.triggers.cron import CronTrigger
import pytz

# æ·»åŠ scriptsç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

# è®¡ç®—æ—¥å¿—ç›®å½•çš„ç»å¯¹è·¯å¾„
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_DIR = os.path.dirname(SCRIPT_DIR)
LOG_DIR = os.path.join(PROJECT_DIR, 'logs')
os.makedirs(LOG_DIR, exist_ok=True)

from fetch_blogs import fetch_all_articles
from analyze_topics import analyze_all_articles, cluster_topics, save_topics
from calculate_heat import calculate_all_heat_scores, save_heat_scores, get_top_topics
from generate_report import generate_report
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(LOG_DIR, 'scheduler.log')),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def load_config():
    """åŠ è½½é…ç½®"""
    config_path = os.path.join(os.path.dirname(__file__), '../config/config.json')
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def run_analysis_pipeline(time_slot: str):
    """
    æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹
    
    Args:
        time_slot: æ—¶é—´æ®µï¼ˆæ—©é—´/åˆé—´/æ™šé—´ï¼‰
    """
    logger.info(f"{'='*60}")
    logger.info(f"å¼€å§‹æ‰§è¡Œ {time_slot} åˆ†æä»»åŠ¡")
    logger.info(f"{'='*60}")
    
    today = datetime.now().strftime('%Y-%m-%d')
    
    try:
        # æ­¥éª¤1ï¼šæŠ“å–RSSï¼ˆè¿‡å»24å°æ—¶å†…çš„æ–‡ç« ï¼‰
        logger.info(f"[1/5] æŠ“å–RSSæºï¼ˆè¿‡å»24å°æ—¶ï¼‰...")
        articles = fetch_all_articles(hours_ago=24)
        
        if not articles:
            logger.warning(f"{time_slot}ï¼šæœªæŠ“å–åˆ°ä»»ä½•æ–‡ç« ï¼Œè·³è¿‡æœ¬æ¬¡åˆ†æ")
            return
        
        logger.info(f"âœ“ æŠ“å–åˆ° {len(articles)} ç¯‡æ–‡ç« ")
        
        # æ£€æŸ¥æœ€å°æ–‡ç« æ•°é˜ˆå€¼
        config = load_config()
        min_threshold = config['output_config']['min_articles_threshold']
        
        if len(articles) < min_threshold:
            logger.warning(f"{time_slot}ï¼šæ–‡ç« æ•°({len(articles)})ä½äºé˜ˆå€¼({min_threshold})ï¼Œå°†é™ä½æ¨èæ ‡å‡†")
        
        # æ­¥éª¤2ï¼šè¯é¢˜æå–ä¸èšç±»
        logger.info(f"[2/5] åˆ†ææ–‡ç« è¯é¢˜...")
        analyzed_articles = analyze_all_articles(articles)
        
        logger.info(f"[3/5] è¯é¢˜èšç±»...")
        topics = cluster_topics(analyzed_articles)
        
        if not topics:
            logger.warning(f"{time_slot}ï¼šæœªè¯†åˆ«åˆ°ä»»ä½•è¯é¢˜ï¼Œè·³è¿‡æœ¬æ¬¡æ¨è")
            return
        
        logger.info(f"âœ“ è¯†åˆ«å‡º {len(topics)} ä¸ªè¯é¢˜")
        
        # ä¿å­˜è¯é¢˜
        save_topics(topics, today)
        
        # æ­¥éª¤3ï¼šè®¡ç®—çƒ­åŠ›å€¼
        logger.info(f"[4/5] è®¡ç®—çƒ­åŠ›å€¼...")
        scored_topics = calculate_all_heat_scores(topics)
        
        # ä¿å­˜çƒ­åŠ›å€¼
        save_heat_scores(scored_topics, today, time_slot)
        
        # æ­¥éª¤4ï¼šç”ŸæˆæŠ¥å‘Š
        logger.info(f"[5/5] ç”Ÿæˆæ¨èæŠ¥å‘Š...")
        
        # æ ¹æ®è¯é¢˜æ•°é‡è°ƒæ•´æ¨èæ•°
        topics_per_report = min(config['output_config']['topics_per_report'], len(scored_topics))
        top_topics = scored_topics[:topics_per_report]
        
        generate_report(top_topics, time_slot, today, len(articles))
        
        logger.info(f"{'='*60}")
        logger.info(f"âœ… {time_slot}ä»»åŠ¡å®Œæˆï¼æ¨èäº† {len(top_topics)} ä¸ªè¯é¢˜")
        logger.info(f"{'='*60}\n")
    
    except Exception as e:
        logger.error(f"âŒ {time_slot}ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)


def job_morning():
    """æ—©é—´ä»»åŠ¡ï¼š9:30"""
    run_analysis_pipeline('æ—©é—´')


def job_afternoon():
    """åˆé—´ä»»åŠ¡ï¼š15:30"""
    run_analysis_pipeline('åˆé—´')


def job_evening():
    """æ™šé—´ä»»åŠ¡ï¼š20:30"""
    run_analysis_pipeline('æ™šé—´')


def start_scheduler():
    """å¯åŠ¨å®šæ—¶è°ƒåº¦å™¨"""
    config = load_config()
    timezone = pytz.timezone(config['timezone'])
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = BlockingScheduler(timezone=timezone)
    
    # è§£ææ—¶é—´é…ç½®
    morning_time = config['schedule']['morning']  # "09:30"
    afternoon_time = config['schedule']['afternoon']  # "15:30"
    evening_time = config['schedule']['evening']  # "20:30"
    
    morning_hour, morning_minute = map(int, morning_time.split(':'))
    afternoon_hour, afternoon_minute = map(int, afternoon_time.split(':'))
    evening_hour, evening_minute = map(int, evening_time.split(':'))
    
    # æ³¨å†Œå®šæ—¶ä»»åŠ¡
    scheduler.add_job(
        job_morning,
        CronTrigger(hour=morning_hour, minute=morning_minute, timezone=timezone),
        id='morning_job',
        name='æ—©é—´åˆ†æ',
        replace_existing=True
    )
    
    scheduler.add_job(
        job_afternoon,
        CronTrigger(hour=afternoon_hour, minute=afternoon_minute, timezone=timezone),
        id='afternoon_job',
        name='åˆé—´åˆ†æ',
        replace_existing=True
    )
    
    scheduler.add_job(
        job_evening,
        CronTrigger(hour=evening_hour, minute=evening_minute, timezone=timezone),
        id='evening_job',
        name='æ™šé—´åˆ†æ',
        replace_existing=True
    )
    
    logger.info("="*60)
    logger.info("ğŸš€ Blog Topic Monitor è°ƒåº¦å™¨å¯åŠ¨æˆåŠŸï¼")
    logger.info("="*60)
    logger.info(f"æ—©é—´ä»»åŠ¡: æ¯å¤© {morning_time}")
    logger.info(f"åˆé—´ä»»åŠ¡: æ¯å¤© {afternoon_time}")
    logger.info(f"æ™šé—´ä»»åŠ¡: æ¯å¤© {evening_time}")
    logger.info(f"æ—¶åŒº: {config['timezone']}")
    logger.info("="*60)
    logger.info("\nç­‰å¾…å®šæ—¶ä»»åŠ¡è§¦å‘...\n")
    
    # å¯åŠ¨è°ƒåº¦å™¨
    try:
        scheduler.start()
    except (KeyboardInterrupt, SystemExit):
        logger.info("\nè°ƒåº¦å™¨å·²åœæ­¢")


if __name__ == '__main__':
    start_scheduler()
