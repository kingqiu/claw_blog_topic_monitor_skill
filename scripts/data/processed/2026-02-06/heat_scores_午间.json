{
  "timestamp": "2026-02-06 午间",
  "total_topics": 12,
  "topics": [
    {
      "canonical_name": "代码库实验快速实施流程",
      "category": "技术探讨",
      "articles": [
        {
          "title": "Quoting Karel D'Oosterlinck",
          "link": "https://simonwillison.net/2026/Feb/6/karel-doosterlinck/#atom-everything",
          "source": "simonwillison.net",
          "summary": "<blockquote cite=\"https://twitter.com/kareldoostrlnck/status/2019477361557926281\"><p>When I want to quickly implement a one-off experiment in a part of the codebase I am unfamiliar with, I get codex to do extensive due diligence. Codex explores relevant slack channels, reads related discussions, fetches experimental branches from those discussions, and cherry picks useful changes for my experiment. All of this gets summarized in an extensive set of notes, with links back to where each piece of information was found. Using these notes, codex wires the experiment and makes a bunch of hyperparameter decisions I couldn’t  possibly make without much more effort.</p></blockquote>\n<p class=\"cite\">&mdash; <a href=\"https://twitter.com/kareldoostrlnck/status/2019477361557926281\">Karel D&#x27;Oosterlinck</a>, I spent $10,000 to automate my research at OpenAI with Codex</p>\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/codex-cli\">codex-cli</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/openai\">openai</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a></p>",
          "content": "<blockquote cite=\"https://twitter.com/kareldoostrlnck/status/2019477361557926281\"><p>When I want to quickly implement a one-off experiment in a part of the codebase I am unfamiliar with, I get codex to do extensive due diligence. Codex explores relevant slack channels, reads related discussions, fetches experimental branches from those discussions, and cherry picks useful changes for my experiment. All of this gets summarized in an extensive set of notes, with links back to where each piece of information was found. Using these notes, codex wires the experiment and makes a bunch of hyperparameter decisions I couldn’t  possibly make without much more effort.</p></blockquote>\n<p class=\"cite\">&mdash; <a href=\"https://twitter.com/kareldoostrlnck/status/2019477361557926281\">Karel D&#x27;Oosterlinck</a>, I spent $10,000 to automate my research at OpenAI with Codex</p>\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/codex-cli\">codex-cli</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/openai\">openai</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a></p>",
          "depth": 0.7,
          "published": "2026-02-06T00:42:22+00:00",
          "category": "实战技巧"
        },
        {
          "title": "Git’s Magic Files",
          "link": "https://nesbitt.io/2026/02/05/git-magic-files.html",
          "source": "nesbitt.io",
          "summary": "Magic files and where to find them: .gitignore, .gitattributes, .mailmap, .git-blame-ignore-revs, .lfsconfig, and more.",
          "content": "<p>A follow-up to my post on <a href=\"https://nesbitt.io/2025/11/26/extending-git-functionality.html\">extending git functionality</a>. Git looks for several special files in your repository that control its behavior. These aren’t configuration files in <code class=\"language-plaintext highlighter-rouge\">.git/</code>, they’re committed files that travel with your code and affect how git treats your files.</p>\n\n<p>If you’re building a tool that works with git repositories, like <a href=\"https://github.com/git-pkgs/git-pkgs\">git-pkgs</a>, you’ll want to ensure you respect these configs.</p>\n\n<h3 id=\"gitignore\">.gitignore</h3>\n\n<p>Patterns of files git should never track. One pattern per line, supports wildcards and directory markers.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>node_modules/\n*.log\n.env\ndist/\n</code></pre></div></div>\n\n<p>Git checks multiple ignore files in order: <code class=\"language-plaintext highlighter-rouge\">.gitignore</code> in each directory, <code class=\"language-plaintext highlighter-rouge\">.git/info/exclude</code> for local-only ignores, and the global ignore file at <code class=\"language-plaintext highlighter-rouge\">~/.config/git/ignore</code> or wherever <code class=\"language-plaintext highlighter-rouge\">core.excludesFile</code> points. Global ignores are good for OS-specific files like <code class=\"language-plaintext highlighter-rouge\">.DS_Store</code> or <code class=\"language-plaintext highlighter-rouge\">Thumbs.db</code> that shouldn’t clutter every project’s <code class=\"language-plaintext highlighter-rouge\">.gitignore</code>.</p>\n\n<p>The pattern matching supports wildcards (<code class=\"language-plaintext highlighter-rouge\">*.log</code>), directory markers (<code class=\"language-plaintext highlighter-rouge\">dist/</code>), negation (<code class=\"language-plaintext highlighter-rouge\">!important.log</code>), and character ranges. The <code class=\"language-plaintext highlighter-ro",
          "depth": 0.8,
          "published": "2026-02-05T10:00:00+00:00",
          "category": "技术探讨"
        }
      ],
      "total_mentions": 2,
      "avg_depth": 0.75,
      "heat_score": 44.5,
      "rank": 1
    },
    {
      "canonical_name": "GPT-2小基座模型的损失优化尝试",
      "category": "技术探讨",
      "articles": [
        {
          "title": "Opus 4.6 and Codex 5.3",
          "link": "https://simonwillison.net/2026/Feb/5/two-new-models/#atom-everything",
          "source": "simonwillison.net",
          "summary": "<p>Two major new model releases today, within about 15 minutes of each other.</p>\n<p>Anthropic <a href=\"https://www.anthropic.com/news/claude-opus-4-6\">released Opus 4.6</a>. Here's <a href=\"https://gist.github.com/simonw/a6806ce41b4c721e240a4548ecdbe216\">its pelican</a>:</p>\n<p><img alt=\"Slightly wonky bicycle frame but an excellent pelican, very clear beak and pouch, nice feathers.\" src=\"https://static.simonwillison.net/static/2026/opus-4.6-pelican.png\" /></p>\n<p>OpenAI <a href=\"https://openai.com/index/introducing-gpt-5-3-codex/\">release GPT-5.3-Codex</a>, albeit only via their Codex app, not yet in their API. Here's <a href=\"https://gist.github.com/simonw/bfc4a83f588ac762c773679c0d1e034b\">its pelican</a>:</p>\n<p><img alt=\"Not nearly as good - the bicycle is a bit mangled, the pelican not nearly as well rendered - it's more of a line drawing.\" src=\"https://static.simonwillison.net/static/2026/codex-5.3-pelican.png\" /></p>\n<p>I've had a bit of preview access to both of these models and to be honest I'm finding it hard to find a good angle to write about them - they're both <em>really good</em>, but so were their predecessors Codex 5.2 and Opus 4.5. I've been having trouble finding tasks that those previous models couldn't handle but the new ones are able to ace.</p>\n<p>The most convincing story about capabilities of the new model so far is Nicholas Carlini from Anthropic talking about Opus 4.6 and <a href=\"https://www.anthropic.com/engineering/building-c-compiler\">Building a C compiler with a team of parallel Claudes</a> - Anthropic's version of Cursor's <a href=\"https://simonwillison.net/2026/Jan/23/fastrender/\">FastRender project</a>.</p>\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/llm-release\">llm-release</a>, <a href=\"https://simonwillison.net/tags/anthropic\">anthropic</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/openai\">openai</a>, <a href=\"https://simonwillison.net/tags/pelican-riding-a-bicycle\">pelican-riding-a-bicycle</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/parallel-agents\">parallel-agents</a>, <a href=\"https://simonwillison.net/tags/c\">c</a>, <a href=\"https://simonwillison.net/tags/nicholas-carlini\">nicholas-carlini</a></p>",
          "content": "<p>Two major new model releases today, within about 15 minutes of each other.</p>\n<p>Anthropic <a href=\"https://www.anthropic.com/news/claude-opus-4-6\">released Opus 4.6</a>. Here's <a href=\"https://gist.github.com/simonw/a6806ce41b4c721e240a4548ecdbe216\">its pelican</a>:</p>\n<p><img alt=\"Slightly wonky bicycle frame but an excellent pelican, very clear beak and pouch, nice feathers.\" src=\"https://static.simonwillison.net/static/2026/opus-4.6-pelican.png\" /></p>\n<p>OpenAI <a href=\"https://openai.com/index/introducing-gpt-5-3-codex/\">release GPT-5.3-Codex</a>, albeit only via their Codex app, not yet in their API. Here's <a href=\"https://gist.github.com/simonw/bfc4a83f588ac762c773679c0d1e034b\">its pelican</a>:</p>\n<p><img alt=\"Not nearly as good - the bicycle is a bit mangled, the pelican not nearly as well rendered - it's more of a line drawing.\" src=\"https://static.simonwillison.net/static/2026/codex-5.3-pelican.png\" /></p>\n<p>I've had a bit of preview access to both of these models and to be honest I'm finding it hard to find a good angle to write about them - they're both <em>really good</em>, but so were their predecessors Codex 5.2 and Opus 4.5. I've been having trouble finding tasks that those previous models couldn't handle but the new ones are able to ace.</p>\n<p>The most convincing story about capabilities of the new model so far is Nicholas Carlini from Anthropic talking about Opus 4.6 and <a href=\"https://www.anthropic.com/engineering/building-c-compiler\">Building a C compiler with a team of parallel Claudes</a> - Anthropic's version of Cursor's <a href=\"https://simonwillison.net/2026/Jan/23/fastrender/\">FastRender project</a>.</p>\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/llm-release\">llm-release</a>, <a href=\"https://simonwillison.net/tags/anthropic\">anthropic</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/openai\">openai</a>, <a href=\"https://simonwillison.net/tags/pelic",
          "depth": 0.5,
          "published": "2026-02-05T20:29:20+00:00",
          "category": "技术探讨"
        },
        {
          "title": "Writing an LLM from scratch, part 32c -- Interventions: removing dropout",
          "link": "https://www.gilesthomas.com/2026/02/llm-from-scratch-32c-interventions-removing-dropout",
          "source": "gilesthomas.com",
          "summary": "<p>This is the second in my series of attempts to improve the loss on my test dataset\n-- interventions, as I'm calling them --\nfor a from-scratch GPT-2 small base model, trained on code based on\n<a href=\"https://sebastianraschka.com/\">Sebastian Raschka</a>'s book\n\"<a href=\"https://www.manning.com/books/build-a-large-language-model-from-scratch\">Build a Large Language Model (from Scratch)</a>\".</p>\n\n<p>Last time around I saw <a href=\"/2026/02/llm-from-scratch-32b-interventions-gradient-clipping\">what gradient clipping can do</a> --\nit improved loss over <a href=\"/2026/02/llm-from-scratch-32a-interventions-baseline-model\">the baseline</a>\nby 0.014, bringing it down from 3.692 to 3.678.  Not much, but it's something!</p>\n\n<p>This time, I wanted to see what happened if we trained without dropout.  Would removing it make\nthe test loss worse, or better?</p>\n<h3 id=\"background\">Background:</h3>\n\n<p>In a blog post last summer about\n<a href=\"https://magazine.sebastianraschka.com/i/170506328/21-removing-dropout\">architectural advances in LLMs since GPT-2</a>,\nSebastian Raschka wrote:</p>\n\n<blockquote>\n  <p>Dropout (2012) is a traditional technique to prevent overfitting by randomly\n  \"dropping out\" (i.e., setting to zero) a fraction of the layer activations or\n  attention scores (Figure 3) during training. However, dropout is rarely used\n  in modern LLMs, and most models after GPT-2 have dropped it (no pun intended).</p>\n  \n  <p>I assume that dropout was originally used in GPT-2 because it was inherited\n  from the original transformer architecture. Researchers likely noticed that\n  it does not really improve LLM performance (I observed the same in my\n  small-scale GPT-2 replication runs). This is likely because LLMs are typically\n  trained for only a single epoch over massive datasets, which is in contrast to\n  the multi-hundred-epoch training regimes for which dropout was first\n  introduced. So, since LLMs see each token only once during training, there is\n  little risk of overfitting.</p>\n</blockquote>\n\n<p>That makes quite a lot of sense.  My own understanding of dropout was that it was\na bit broader than just preventing overfitting -- it seemed to me to be similar\nto the\n<a href=\"/2025/03/dropout-and-mandatory-vacation\">mandatory vacation policies that financial firms user to prevent over-dependence on individuals</a>.\nMy instinct was that having knowledge distributed across different weights in the\nmodel was good in and of itself, even beyond its benefit on multiple-epoch training.</p>\n\n<p>But it is quite a high price to pay.\nWith the training parameters we've been using we're literally discarding 10% of our calculations' results --\nattention weights, feed-forward neuron activations, and so on -- as we do the forward pass.\nIt's easy to see why it would harm training.</p>\n\n<p>Let's give it a go.</p>\n\n<h3 id=\"the-training-run\">The training run</h3>\n\n<p>The nice thing about this one is that, unlike the gradient clipping experiment,\nI didn't have to write any new code.  The dropout level was already controlled by\na setting in the <a href=\"https://github.com/gpjt/ddp-base-model-from-scratch/blob/main/runs/8xa100m40-remove-dropout/model.json\"><code>model.json</code> file</a>,\nso by setting that to zero for this run, I could just kick it off and let it\ndo its thing while I worked on something else:</p>\n\n<p>Here's what the training run chart looked like (please disregard the stuff about\ngrad norms in the title and the axis -- I'll remove that for the next train):</p>\n\n<p><img alt=\"Training chart for zero-dropout run\" src=\"/post-assets/llm-from-scratch-32c-interventions-removing-dropout/training-chart.png\" title=\"Training chart for zero-dropout run\" /></p>\n\n<p>As you can see, we still have loss spikes, including one just after global step 20,000\nthat lasts for several checkpoint periods of 617 steps.  I imagine gradient clipping\nmight have helped with that, but I'm very deliberately testing each intervention in\nisolation.</p>\n\n<p>At the end of the training run, we got this:</p>\n\n<div class=\"codehilite\">\n<pre><span></span><code><span class=\"go\">Training complete in 11,376.067 seconds</span>\n<span class=\"go\">Tokens seen: 3,260,252,160</span>\n<span class=\"go\">Throughput: 286,589 tokens/second</span>\n<span class=\"go\">Final train loss: 3.621</span>\n</code></pre>\n</div>\n\n<p>So, interestingly, it took 967 seconds -- about 16 minutes -- less time than the\ngradient clipping run, and about 15 minutes less than the baseline train.  So\nwhile gradient clipping added on a small amount of time (or maybe that was just noise),\ndropping dropout certainly seems to speed things up!  I guess there's quite a lot of\nwork involved in generating and applying the random masks that drop things out as we're\ndoing the forward pass.</p>\n\n<p>Anyway, with the model trained, it was time to download it,\n<a href=\"https://huggingface.co/gpjt/8xa100m40-remove-dropout\">upload it to Hugging Face Hub</a>, and run the evals.</p>\n\n<h3 id=\"evals\">Evals</h3>\n\n<p>Firstly, the smoke test, where it just needs to continue the sequence <code>Every effort moves you</code>,\nit came up with something reasonably coherent:</p>\n\n<div class=\"codehilite\">\n<pre><span></span><code><span class=\"gp\">giles@perry:~/Dev/ddp-base-model-from-scratch (main)$ </span>uv<span class=\"w\"> </span>run<span class=\"w\"> </span>test_smoke.py<span class=\"w\"> </span>runs/8xa100m40-remove-dropout/model.json<span class=\"w\"> </span>runs/8xa100m40-remove-dropout/checkpoints/best/model.safetensors\n<span class=\"go\">Every effort moves you to make the world a better place.</span>\n<span class=\"go\">As an international student of the arts in the UK,</span>\n</code></pre>\n</div>\n\n<p>...but it was on the test of the loss on the training set that it was most impressive:</p>\n\n<div class=\"codehilite\">\n<pre><span></span><code><span class=\"gp\">giles@perry:~/Dev/ddp-base-model-from-scratch (main)$ </span>uv<span class=\"w\"> </span>run<span class=\"w\"> </span>test_loss.py<span class=\"w\"> </span>datasets/<span class=\"w\"> </span>runs/8xa100m40-remove-dropout/model.json<span class=\"w\"> </span>runs/8xa100m40-remove-dropout/checkpoints/best/model.safetensors\n<span class=\"go\">Fetching 4 files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00&lt;00:00, 1086.75it/s]</span>\n<span class=\"go\">100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3200/3200 [04:54&lt;00:00, 10.87it/s]</span>\n<span class=\"go\">Loss against our test dataset: 3.641</span>\n</code></pre>\n</div>\n\n<p>That's a bigger improvement on the baseline train's 3.692 than gradient clipping:\n0.051, which is more than three times the improvement!</p>\n\n<p>Let's start keeping a table of these:</p>\n\n<table>\n<thead>\n<tr>\n  <th></th>\n  <th>Test set loss</th>\n  <th>Improvement vs baseline</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n  <td>8xa100m40-baseline</td>\n  <td>3.692</td>\n  <td>-</td>\n</tr>\n<tr>\n  <td>8xa100m40-gradient-clipping</td>\n  <td>3.678</td>\n  <td>0.014</td>\n</tr>\n<tr>\n  <td>8xa100m40-remove-dropout</td>\n  <td>3.641</td>\n  <td>0.051</td>\n</tr>\n</tbody>\n</table>\n\n<p>Now, of course, we don't know how these different interventions combine together --\nit would be naive to think that if we did both gradient clipping and dropout\nremoval, we'd get a total loss reduction of 0.014 + 0.051 -- but, especially with that\nlong-lived loss spike in our training run -- it does feel like they might play well\ntogether.</p>\n\n<h3 id=\"wrapping-up\">Wrapping up</h3>\n\n<p>So, that's dropout covered.  Which one next?  I think a nice easy one that I should\nbe able to get done on a Friday will be adding bias to the attention weight calculations.\nLet's give that a go and see if it makes things worse or better!</p>\n\n<p>Stay tuned...</p>",
          "content": "<p>This is the second in my series of attempts to improve the loss on my test dataset\n-- interventions, as I'm calling them --\nfor a from-scratch GPT-2 small base model, trained on code based on\n<a href=\"https://sebastianraschka.com/\">Sebastian Raschka</a>'s book\n\"<a href=\"https://www.manning.com/books/build-a-large-language-model-from-scratch\">Build a Large Language Model (from Scratch)</a>\".</p>\n\n<p>Last time around I saw <a href=\"/2026/02/llm-from-scratch-32b-interventions-gradient-clipping\">what gradient clipping can do</a> --\nit improved loss over <a href=\"/2026/02/llm-from-scratch-32a-interventions-baseline-model\">the baseline</a>\nby 0.014, bringing it down from 3.692 to 3.678.  Not much, but it's something!</p>\n\n<p>This time, I wanted to see what happened if we trained without dropout.  Would removing it make\nthe test loss worse, or better?</p>\n<h3 id=\"background\">Background:</h3>\n\n<p>In a blog post last summer about\n<a href=\"https://magazine.sebastianraschka.com/i/170506328/21-removing-dropout\">architectural advances in LLMs since GPT-2</a>,\nSebastian Raschka wrote:</p>\n\n<blockquote>\n  <p>Dropout (2012) is a traditional technique to prevent overfitting by randomly\n  \"dropping out\" (i.e., setting to zero) a fraction of the layer activations or\n  attention scores (Figure 3) during training. However, dropout is rarely used\n  in modern LLMs, and most models after GPT-2 have dropped it (no pun intended).</p>\n  \n  <p>I assume that dropout was originally used in GPT-2 because it was inherited\n  from the original transformer architecture. Researchers likely noticed that\n  it does not really improve LLM performance (I observed the same in my\n  small-scale GPT-2 replication runs). This is likely because LLMs are typically\n  trained for only a single epoch over massive datasets, which is in contrast to\n  the multi-hundred-epoch training regimes for which dropout was first\n  introduced. So, since LLMs see each token only once during training, there is\n  little risk of o",
          "depth": 0.9,
          "published": "2026-02-05T23:35:00+00:00",
          "category": "技术探讨"
        }
      ],
      "total_mentions": 2,
      "avg_depth": 0.7,
      "heat_score": 43.0,
      "rank": 2
    },
    {
      "canonical_name": "AI行业潜在危机",
      "category": "行业动态",
      "articles": [
        {
          "title": "Is the Great AI meltdown imminent? [NSFW]",
          "link": "https://garymarcus.substack.com/p/is-the-great-ai-meltdown-imminent",
          "source": "garymarcus.substack.com",
          "summary": "A $100 billion dollar deal that was propping up the industry just disappeared",
          "content": "<div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!RzuG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f62dfb5-9c11-4395-b355-fd873644a449_713x965.png\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"965\" src=\"https://substackcdn.com/image/fetch/$s_!RzuG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f62dfb5-9c11-4395-b355-fd873644a449_713x965.png\" width=\"713\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg fill=\"none\" height=\"20\" stroke=\"var(--color-fg-primary)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\" viewBox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><g><title></title><path d=\"M2.53001 7.81595C3.49179 4.73911 6.43281 2.5 9.91173 2.5C13.1684 2.5 15.9537 4.46214 17.0852 7.23684L17.6179 8.67647M17.6179 8.67647L18.5002 4.26471M17.6179 8.67647L13.6473 6.91176M17.4995 12.1841C16.5378 15.2609 13.5967 17.5 10.1178 17.5C6.86118 17.5 4.07589 15.5379 2.94432 12.7632L2.41165 11.3235M2.41165 11.3235L1.5293 15.7353M2.41165 11.3235L6.38224 13.0882\"></path></g></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></",
          "depth": 1.0,
          "published": "2026-02-05T15:11:22+00:00",
          "category": "行业动态"
        }
      ],
      "total_mentions": 1,
      "avg_depth": 1.0,
      "heat_score": 41.0,
      "rank": 3
    },
    {
      "canonical_name": "AI代理的日常应用",
      "category": "技术探讨",
      "articles": [
        {
          "title": "Mitchell Hashimoto: My AI Adoption Journey",
          "link": "https://simonwillison.net/2026/Feb/5/ai-adoption-journey/#atom-everything",
          "source": "simonwillison.net",
          "summary": "<p><strong><a href=\"https://mitchellh.com/writing/my-ai-adoption-journey\">Mitchell Hashimoto: My AI Adoption Journey</a></strong></p>\nSome really good and unconventional tips in here for getting to a place with coding agents where they demonstrably improve your workflow and productivity. I particularly liked:</p>\n<ul>\n<li>\n<p><a href=\"https://mitchellh.com/writing/my-ai-adoption-journey#step-2-reproduce-your-own-work\">Reproduce your own work</a> - when learning to use coding agents Mitchell went through a period of doing the work manually, then recreating the same solution using agents as an exercise:</p>\n<blockquote>\n<p>I literally did the work twice. I'd do the work manually, and then I'd fight an agent to produce identical results in terms of quality and function (without it being able to see my manual solution, of course).</p>\n</blockquote>\n</li>\n<li>\n<p><a href=\"https://mitchellh.com/writing/my-ai-adoption-journey#step-3-end-of-day-agents\">End-of-day agents</a> - letting agents step in when your energy runs out:</p>\n<blockquote>\n<p>To try to find some efficiency, I next started up a new pattern: <strong>block out the last 30 minutes of every day to kick off one or more agents.</strong> My hypothesis was that <em>perhaps</em> I could gain some efficiency if the agent can make some <em>positive progress</em> in the times I can't work anyways.</p>\n</blockquote>\n</li>\n<li>\n<p><a href=\"https://mitchellh.com/writing/my-ai-adoption-journey#step-4-outsource-the-slam-dunks\">Outsource the Slam Dunks</a> - once you know an agent can likely handle a task, have it do that task while you work on something more interesting yourself.</p>\n</li>\n</ul>\n\n    <p><small></small>Via <a href=\"https://news.ycombinator.com/item?id=46903558\">Hacker News</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/mitchell-hashimoto\">mitchell-hashimoto</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a></p>",
          "content": "<p><strong><a href=\"https://mitchellh.com/writing/my-ai-adoption-journey\">Mitchell Hashimoto: My AI Adoption Journey</a></strong></p>\nSome really good and unconventional tips in here for getting to a place with coding agents where they demonstrably improve your workflow and productivity. I particularly liked:</p>\n<ul>\n<li>\n<p><a href=\"https://mitchellh.com/writing/my-ai-adoption-journey#step-2-reproduce-your-own-work\">Reproduce your own work</a> - when learning to use coding agents Mitchell went through a period of doing the work manually, then recreating the same solution using agents as an exercise:</p>\n<blockquote>\n<p>I literally did the work twice. I'd do the work manually, and then I'd fight an agent to produce identical results in terms of quality and function (without it being able to see my manual solution, of course).</p>\n</blockquote>\n</li>\n<li>\n<p><a href=\"https://mitchellh.com/writing/my-ai-adoption-journey#step-3-end-of-day-agents\">End-of-day agents</a> - letting agents step in when your energy runs out:</p>\n<blockquote>\n<p>To try to find some efficiency, I next started up a new pattern: <strong>block out the last 30 minutes of every day to kick off one or more agents.</strong> My hypothesis was that <em>perhaps</em> I could gain some efficiency if the agent can make some <em>positive progress</em> in the times I can't work anyways.</p>\n</blockquote>\n</li>\n<li>\n<p><a href=\"https://mitchellh.com/writing/my-ai-adoption-journey#step-4-outsource-the-slam-dunks\">Outsource the Slam Dunks</a> - once you know an agent can likely handle a task, have it do that task while you work on something more interesting yourself.</p>\n</li>\n</ul>\n\n    <p><small></small>Via <a href=\"https://news.ycombinator.com/item?id=46903558\">Hacker News</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwil",
          "depth": 0.8,
          "published": "2026-02-05T23:39:07+00:00",
          "category": "实战技巧"
        }
      ],
      "total_mentions": 1,
      "avg_depth": 0.8,
      "heat_score": 40.0,
      "rank": 4
    },
    {
      "canonical_name": "图像模糊信息保留分析",
      "category": "技术探讨",
      "articles": [
        {
          "title": "It's all a blur",
          "link": "https://lcamtuf.substack.com/p/its-all-a-blur",
          "source": "lcamtuf.substack.com",
          "summary": "If you follow information security discussions on the internet, you might have heard that blurring an image is not a good way of redacting its contents.",
          "content": "<p>If you follow information security discussions on the internet, you might have heard that blurring an image is not a good way of redacting its contents. This is supposedly because blurring algorithms are reversible.</p><p>But then, it&#8217;s not wrong to scratch your head. Blurring amounts to averaging the underlying pixel values. If you average two numbers, there&#8217;s no way of knowing if you&#8217;ve started with 1 + 5 or 3 + 3. In both cases, the arithmetic mean is the same and the original information appears to be lost. So, is the advice wrong?</p><p>Well, yes and no! There are ways to achieve non-reversible blurring using deterministic algorithms. That said, in many cases, the algorithm preserves far more information than would appear to the naked eye &#8212; and does it in a pretty unexpected way. In today&#8217;s article, we&#8217;ll build a rudimentary blur algorithm and then pick it apart.</p><h3>One-dimensional moving average</h3><p>If blurring is the same as averaging, then the simplest algorithm we can choose is the moving mean. We take a fixed-size window and replace each pixel value with the arithmetic mean of <em>n</em> pixels in its neighborhood. For <em>n = 5</em>, the process is shown below:</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" href=\"https://substackcdn.com/image/fetch/$s_!D1oj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0087865d-a763-4b28-b680-029eb525ae0e_2050x2650.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><source type=\"image/webp\" /><img alt=\"\" class=\"sizing-normal\" height=\"1882\" src=\"https://substackcdn.com/image/fetch/$s_!D1oj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0087865d-a763-4b28-b680-029eb525ae0e_2050x2650.jpeg\" width=\"1456\" /><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><b",
          "depth": 0.8,
          "published": "2026-02-06T03:38:17+00:00",
          "category": "技术探讨"
        }
      ],
      "total_mentions": 1,
      "avg_depth": 0.8,
      "heat_score": 40.0,
      "rank": 5
    },
    {
      "canonical_name": "太空数据中心经济性分析",
      "category": "技术探讨",
      "articles": [
        {
          "title": "Elon Musk - \"In 36 months, the cheapest place to put AI will be space”",
          "link": "https://www.dwarkesh.com/p/elon-musk",
          "source": "dwarkesh.com",
          "summary": "&#8220;Those who live in software land are about to have a hard lesson in hardware.&#8221;",
          "content": "<p>In this episode, John and I got to do a real deep-dive with Elon. We discuss the economics of orbital data centers, the difficulties of scaling power on Earth, what it would take to manufacture humanoids at high-volume in America, xAI&#8217;s business and alignment plans, DOGE, and much more.</p><p>Watch on <a href=\"https://youtu.be/BYXbuik3dgA\">YouTube</a>; listen on <a href=\"https://podcasts.apple.com/us/podcast/elon-musk-in-36-months-the-cheapest-place-to-put-ai/id1516093381?i=1000748400389\">Apple Podcasts</a> or <a href=\"https://open.spotify.com/episode/4nah0x1qQF2hxgJnv8PlmN?si=_U3Ab9A0TOu49wfX6oPQdg\">Spotify</a>.</p><div class=\"youtube-wrap\" id=\"youtube2-BYXbuik3dgA\"><div class=\"youtube-inner\"></div></div><h3>Sponsors</h3><ul><li><p><a href=\"https://mercury.com/personal-banking\">Mercury</a> just started offering personal banking! I&#8217;m already banking with Mercury for business purposes, so getting to bank with them for my personal life makes everything so much simpler. Apply now at <a href=\"https://mercury.com/personal-banking\">mercury.com/personal-banking</a></p></li><li><p><a href=\"https://janestreet.com/dwarkesh\">Jane Street</a> sent me a new puzzle last week: they trained a neural net, shuffled all 96 layers, and asked me to put them back in order. I tried but&#8230; I didn&#8217;t quite nail it. If you&#8217;re curious, or if you think you can do better, you should take a stab at <a href=\"https://janestreet.com/dwarkesh\">janestreet.com/dwarkesh</a></p></li><li><p><a href=\"https://labelbox.com/dwarkesh\">Labelbox</a> can get you robotics and RL data at scale. Labelbox starts by helping you define your ideal data distribution, and then their massive Alignerr network collects frontier-grade data that you can use to train your models. Learn more at <a href=\"https://labelbox.com/dwarkesh\">labelbox.com/dwarkesh</a></p></li></ul><h2>Timestamps</h2><p>00:00:00 - Orbital data centers</p><p>00:36:46 - Grok and alignment</p><p>00:59:56 - xAI&#8217;s business p",
          "depth": 0.8,
          "published": "2026-02-05T16:45:08+00:00",
          "category": "趋势观点"
        }
      ],
      "total_mentions": 1,
      "avg_depth": 0.8,
      "heat_score": 40.0,
      "rank": 6
    },
    {
      "canonical_name": "ListView列宽变更阻止技巧",
      "category": "技术探讨",
      "articles": [
        {
          "title": "How can I prevent the user from changing the widths of ListView columns in version 5 of the common controls?",
          "link": "https://devblogs.microsoft.com/oldnewthing/20260205-00/?p=112042",
          "source": "devblogs.microsoft.com/oldnewthing",
          "summary": "<p>Deny changes to the width.</p>\n<p>The post <a href=\"https://devblogs.microsoft.com/oldnewthing/20260205-00/?p=112042\">How can I prevent the user from changing the widths of ListView columns in version 5 of the common controls?</a> appeared first on <a href=\"https://devblogs.microsoft.com/oldnewthing\">The Old New Thing</a>.</p>",
          "content": "<p>Last time, we saw how to <a href=\"https://devblogs.microsoft.com/oldnewthing/20260204-00/?p=112037\" title=\"How can I prevent the user from changing the widths of ListView columns?\"> prevent the user from changing the widths of ListView columns</a>, but the technique required version 6 of the common controls. What if you&#8217;re stuck in the dark ages and have to use version 5?</p>\n<p>You can deny the ability to change the width of a header item by listening for <code>HDN_ITEM­CHANGING</code> and returning 1 to deny the change if there is a change to the width.</p>\n<pre>case WM_NOTIFY:\n    {\n        auto hdr = (NMHDR*)lParam;\n        if (hdr-&gt;code == HDN_ITEMCHANGING) {\n            auto header = (NMHEADER*)lParam;\n            if (header-&gt;pitem-&gt;mask &amp; HDI_WIDTH) {\n                return 1;\n            }\n        }\n    }\n    return 0;\n</pre>\n<p>The above code assumes that it is running in a window procedure. If it&#8217;s running in a dialog procedure, then you need to set the dialog message result.</p>\n<pre>case WM_NOTIFY:\n    {\n        auto hdr = (NMHDR*)lParam;\n        if (hdr-&gt;code == HDN_ITEMCHANGING) {\n            auto header = (NMHEADER*)lParam;\n            if (header-&gt;pitem-&gt;mask &amp; HDI_WIDTH) {\n                <span style=\"border-bottom: none;\">SetWindowLongPtr(hDlg, DWLP_MSGRESULT, 1);</span>\n                <span style=\"border-top: none;\">return TRUE;                              </span>\n            }\n        }\n    }\n    return FALSE;\n</pre>\n<p>Note that if somebody tries to change both the width and the text, this will reject the entire change. There is, unfortunately, no way to selectively reject the change: Modifications to <code>header-&gt;pitem-&gt;mask</code> are ignored.¹</p>\n<p>However, all is not lost. Even though changes to the mask are ignored, changes to the <code>pitem-&gt;cxy</code> are still honored, so we can just set the width back to whatever the width is right now.</p>\n<pre>case WM_NOTIFY:\n    {\n        auto hd",
          "depth": 0.8,
          "published": "2026-02-05T15:00:00+00:00",
          "category": "实战技巧"
        }
      ],
      "total_mentions": 1,
      "avg_depth": 0.8,
      "heat_score": 40.0,
      "rank": 7
    },
    {
      "canonical_name": "模型性能比较",
      "category": "技术探讨",
      "articles": [
        {
          "title": "Fibonacci number certificates",
          "link": "https://www.johndcook.com/blog/2026/02/05/fibonacci-certificate/",
          "source": "johndcook.com",
          "summary": "<p>Suppose I give you a big number F and claim that F is a Fibonacci number. How could you confirm this? Before I go further, let me say what this post is really about. It&#8217;s not about Fibonacci numbers so much as it is about proofs and certificates. There&#8217;s no market for large Fibonacci numbers, and certainly [&#8230;]</p>\nThe post <a href=\"https://www.johndcook.com/blog/2026/02/05/fibonacci-certificate/\">Fibonacci number certificates</a> first appeared on <a href=\"https://www.johndcook.com/blog\">John D. Cook</a>.",
          "content": "<p>Suppose I give you a big number <em>F</em> and claim that <em>F</em> is a Fibonacci number. How could you confirm this?</p>\n<p>Before I go further, let me say what this post is really about. It&#8217;s not about Fibonacci numbers so much as it is about proofs and certificates. There&#8217;s no market for large Fibonacci numbers, and certainly no need to quickly verify that a number is a Fibonacci number.</p>\n<p>You could write a program to generate Fibonacci numbers, and run it until it either produces <em>F</em> , in which case you know <em>F</em> is a Fibonacci number, or the program produces a larger number than <em>F</em> without having produced <em>F</em>, in which case you know it&#8217;s not a Fibonacci number. But there&#8217;s a faster way.</p>\n<p>A certificate is data that allows you to confirm a solution to a problem in less time, usually far less time, than it took to generate the solution. For example, <a href=\"https://www.johndcook.com/blog/2023/01/03/pratt-certificate/\">Pratt certificates</a> give you a way to prove that a number is prime. For a large prime, you could verify its Pratt certificate much faster than directly trying to prove the number is prime.</p>\n<p>There is a theorem that says a number <em>f</em> is a Fibonacci number if and only if one of 5<em>f</em><sup>2</sup> ± 4 is a perfect square. So in addition to <em>F</em> another number <em>r</em> that is a certificate that <em>F</em> is a Fibonacci number. You compute</p>\n<p style=\"padding-left: 40px;\"><em>N</em> = 5<em>F</em>² − <em>r</em>²</p>\n<p>and if <em>N</em> is equal to 4 or −4, you know that <em>F</em> is a Fibonacci number. Otherwise it is not.</p>\n<p>Here&#8217;s a small example. Suppose I give you (12586269025, 28143753123) and claim that the first number is a Fibonacci number and the second number is its certificate. You can compute</p>\n<p style=\"padding-left: 40px;\">5 × 12586269025² − 28143753123²</p>\n<p>and get −4, verifying the claim.</p>\n<p>Certificates are all about th",
          "depth": 0.7,
          "published": "2026-02-05T17:14:20+00:00",
          "category": "技术探讨"
        }
      ],
      "total_mentions": 1,
      "avg_depth": 0.7,
      "heat_score": 37.0,
      "rank": 8
    },
    {
      "canonical_name": "SpaceX与xAI收购事件",
      "category": "行业动态",
      "articles": [
        {
          "title": "Notes on Space GPUs",
          "link": "https://www.dwarkesh.com/p/notes-on-space-gpus",
          "source": "dwarkesh.com",
          "summary": "Turning my Elon prep into a blog post",
          "content": "<p></p><p>John Collison and I <a href=\"https://www.dwarkesh.com/p/elon-musk\">just interviewed Elon</a>. The interview was recorded before we knew that SpaceX was acquiring xAI, so the fact that our first topic was space GPUs now feels all the more relevant.</p><p>As I was preparing to interview Elon, I put together some notes and a <a href=\"https://docs.google.com/spreadsheets/d/1fa48HAwXaboEXNOrAj-xJF2Vv_xxQZjAtgoTu0FnnlY/edit?usp=sharing\">spreadsheet</a> to help me think through orbital datacenters. I turned those notes into this blog post.</p><p>Even if orbital data centers don&#8217;t make sense yet, in the long run the singularity is clearly moving into space. Earth intercepts about one two-billionth of the sun&#8217;s total output. If AI scaling continues, compute will eventually move to where the energy is. So space GPUs are fun to think about, because they give you a sneak peek at the future. Whether that future arrives in 2030, 2040, or 2050 is another question.</p><p><strong>Please take everything below with grains of salt&#8212;grains so big that you might confuse them for rocks. Assume all the numbers are wrong.</strong> Every paragraph below covers a topic that would take an actual expert a week to properly evaluate. What you&#8217;ll find here is what a professional podcaster has pieced together from conversations with LLMs and some very generous people who talked to me before the interview. Thanks to <a href=\"https://x.com/CJHandmer\">Casey Handmer</a>, <a href=\"https://x.com/PhilipJohnston\">Philip Johnston</a>, <a href=\"https://x.com/ezrafeilden\">Ezra Feilden</a>, <a href=\"https://x.com/andrewmccalip\">Andrew McCalip</a>, <a href=\"https://x.com/vinayramasesh\">Vinay Ramasesh</a> and the team at <a href=\"https://www.kineticpartners.com/\">Kinetic Partnership</a> for all their help.</p><h2><strong>Why orbital data centers?</strong></h2><p>The whole reason to go to space is energy. Yes, panels in space get about 40% more irradiance&#8212;but the real advant",
          "depth": 0.6,
          "published": "2026-02-05T18:26:47+00:00",
          "category": "趋势观点"
        },
        {
          "title": "What happened to Conner hard drives",
          "link": "https://dfarq.homeip.net/what-happened-to-conner-hard-drives/?utm_source=rss&utm_medium=rss&utm_campaign=what-happened-to-conner-hard-drives",
          "source": "dfarq.homeip.net",
          "summary": "<p>Conner Peripherals was founded June 17, 1985 by Seagate Technology co-founder Finis Conner, in San Jose. On Sep. 20, 1995, Conner agreed to merge with Seagate in a deal worth $1 billion. The deal closed February 5, 1996. At the</p>\n<p>The post <a href=\"https://dfarq.homeip.net/what-happened-to-conner-hard-drives/\">What happened to Conner hard drives</a> appeared first on <a href=\"https://dfarq.homeip.net\">The Silicon Underground</a>.</p>",
          "content": "<p>Conner Peripherals was founded June 17, 1985 by Seagate Technology co-founder Finis Conner, in San Jose. On Sep. 20, 1995, Conner agreed to merge with Seagate in a deal worth $1 billion. The deal closed February 5, 1996. At the</p>\n<p>The post <a href=\"https://dfarq.homeip.net/what-happened-to-conner-hard-drives/\">What happened to Conner hard drives</a> appeared first on <a href=\"https://dfarq.homeip.net\">The Silicon Underground</a>.</p>",
          "depth": 0.6,
          "published": "2026-02-05T12:00:49+00:00",
          "category": "行业动态"
        }
      ],
      "total_mentions": 2,
      "avg_depth": 0.6,
      "heat_score": 35.0,
      "rank": 9
    },
    {
      "canonical_name": "追求个人兴趣与个性展示",
      "category": "行业动态",
      "articles": [
        {
          "title": "How to stop being boring",
          "link": "https://www.joanwestenberg.com/how-to-stop-being-boring/",
          "source": "joanwestenberg.com",
          "summary": "<p>The most interesting people I know aren&apos;t trying to be interesting. </p><p>Thank God. </p><p>They&apos;re saying what they actually think and wearing what they actually like, pursuing hobbies that genuinely fascinate them, regardless of whether those hobbies are cool. The most mind-numbingly boring people I know are</p>",
          "content": "<img alt=\"How to stop being boring\" src=\"https://images.unsplash.com/photo-1548159417-f283998827c1?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDgxfHxhYnN0cmFjdHxlbnwwfHx8fDE3NzAzMTg2NjN8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=2000\" /><p>The most interesting people I know aren&apos;t trying to be interesting. </p><p>Thank God. </p><p>They&apos;re saying what they actually think and wearing what they actually like, pursuing hobbies that genuinely fascinate them, regardless of whether those hobbies are cool. The most mind-numbingly boring people I know are working overtime to seem interesting: curating their book recommendations, workshopping their opinions to be provocative but not too provocative. </p><p>The effort is palpable. And the effort is exactly what makes them forgettable.</p><p>I&apos;ve come to believe that boring = personality edited down to nothing. Somewhere along the way, too many of us learned to sand off our weird edges, to preemptively remove anything that might make someone uncomfortable or make us seem difficult to be around.</p><p>And the result = boredom.</p><h2 id=\"youve-been-editing-yourself\">You&apos;ve been editing yourself</h2><p>Erving Goffman wrote in 1959 about how we all perform versions of ourselves depending on context. What&apos;s less normal is when the performance becomes the only thing left. When you&apos;ve been editing yourself for so long that you&apos;ve forgotten what the original draft looked like.</p><p>This happens gradually. In middle school, you learn that certain enthusiasms are embarrassing. In high school, you learn which opinions are acceptable in your social group. In college, you refine your persona further. By the time you&apos;re an adult, you&apos;ve become so skilled at reading rooms and ajusting accordingly that you don&apos;t even notice you&apos;re doing it. You&apos;ve automated your own inauthenticity.</p><p>This process feels like maturity, or it feels the way we thi",
          "depth": 0.7,
          "published": "2026-02-05T19:11:57+00:00",
          "category": "趋势观点"
        }
      ],
      "total_mentions": 1,
      "avg_depth": 0.7,
      "heat_score": 32.0,
      "rank": 10
    },
    {
      "canonical_name": "科幻理论与必然性",
      "category": "行业动态",
      "articles": [
        {
          "title": "Pluralistic: All laws are local (05 Feb 2026)",
          "link": "https://pluralistic.net/2026/02/05/contingency/",
          "source": "pluralistic.net",
          "summary": "Today's links All laws are local: And no law knows how evitable it is. Hey look at this: Delights to delectate. Object permanence: Whisky PC; Anitfeatures; Silicon Roundabout; Steampunk Etch-A-Sketch; MLMs as mirror-world organizers. Upcoming appearances: Where to find me. Recent appearances: Where I've been. Latest books: You keep readin' em, I'll keep writin' 'em. Upcoming books: Like I said, I'll keep writin' 'em. Colophon: All the rest. All laws are local (permalink) About halfway through Thomas Piketty's 2013 barnstorming Capital in the 21st Century, Piketty tosses off a little insight that skewered me on the spot and never let me go: the notion that any societal condition that endures beyond a generation becomes \"eternal\" in the popular consciousness: https://memex.craphound.com/2014/06/24/thomas-pikettys-capital-in-the-21st-century/ Piketty was referring to \"primogeniture,\" the ancient practice of automatically passing the family fortune onto the eldest son (or, if no son was available, the eldest nephew). Primogeniture did important work by keeping dynastic fortunes intact, rather than dividing them up among all children of some baron or lord or other guillotineable monster. Primogeniture persisted until the age of colonization, when Europe's \"great powers\" stole the rest of the world. In that moment, the size of Europe's great fortunes expanded by orders of magnitude. This vast increase in the wealth of Europe's most murderous, remorseless looters made primogeniture obsolete. There was so much blood-soaked money available to the nobility that every son could found a \"great house.\" After a couple generations' worth of this, the colonies were exhausted. There were no more lands to conquer, which meant that every son could no longer expect to found his own fortune. But for these chinless masters of the universe, a world where every son of every rich man wouldn't get his own dynasty was incomprehensible. To do otherwise was literally unimaginable. It was unnatural. For Piketty, this explained World War I: the world's chinless inbred monsters embarking upon an orgy of bloodletting to relieve one another of the lands &#8211; and peoples &#8211; they'd claimed as their property in order to carry on the \"eternal\" tradition of every son starting his own fortune. It's a very important idea, and a provocative explanation for one of the 20th Century's defining events. That's why it struck me so hard when I first read it, but the reason it stuck with me for the decade-plus since I encountered that it is a vital observation about the human condition: as a species, we forget so much. Something that was commonplace a generation ago becomes unimaginable today, and vice versa. Even people who lived through those years forget who they were and what they took for granted in those days. Think, for example, of all those evangelicals who would vote for Satan himself if he promised to hang any woman who obtained an abortion; the same evangelicals who, just a few decades ago, viewed anti-abortionism as a politically suspect form of crypto-papacy: https://pluralistic.net/2021/12/18/schizmogenesis/ Perhaps the reason Piketty's primogeniture-based explanation for WWI struck me so forcefully and durably is that I imbibed a prodigious amount of science fiction as a boy, including the aphorism that \"all laws are local, and no law knows how local it is\": https://locusmag.com/feature/cory-doctorow-a-cosmopolitan-literature-for-the-cosmopolitan-web/ In other words, things that seem eternal and innate to the human condition to you are apt to have been invented ten minutes before you started to notice the world around you and might seem utterly alien to your children. As Douglas Adams put it: Anything that is in the world when you're born is normal and ordinary and is just a natural part of the way the world works. Anything that's invented between when you're fifteen and thirty-five is new and exciting and revolutionary and you can probably get a career in it. Anything invented after you're thirty-five is against the natural order of things. https://en.wikiquote.org/wiki/Douglas_Adams This notion is much on my mind right now because the world is (to me, at least) unassailably in a state of change, and everything is up for grabs. Europe went from 15 years behind on its climate goals to ten years ahead of schedule after the supply of Russian gas dried up and Europeans found themselves shivering in the dark. The massive leap in EU solar means that the (seemingly) all-powerful fossil fuel lobby has absolutely, comprehensively eaten shit, something that was unthinkable just a few years ago: https://pluralistic.net/2025/09/23/our-friend-the-electron/#to-every-man-his-castle Indeed, this happened so fast that many people (including many Europeans) haven't even noticed that it happened. Back in December, when I was at CCC in Hamburg, I talked to a bunch of European activists, close watchers of the Commission and the Parliament, who were completely convinced that Europe would never spurn the fossil fuel sector &#8211; despite the fact that it had already happened. Indeed, it may be that intimate familiarity with European politics is a liability when things change. Spend enough time observing up close how supine European politicians and their Eurocrats are and you may find yourself so reflexively conditioned to view them as spineless corporate lackeys and thus unable to notice when they finally dig up a vertebra or two. Smart financiers are familiar with Stein's Law: \"anything that can't go on forever eventually stops.\" Change happens. Eternal verities might be fifteen minutes older than you. Pink used to be the color of ferocious masculinity, whereas blue was so girly as to be practically titular: https://en.wikipedia.org/wiki/Gendered_associations_of_pink_and_blue Real talk: I have serious, debilitating chronic pain. One of the reasons I'm so prolific is that the only time I stop noticing how much I hurt is when I'm lost in work (compartmentalization is a hell of a drug, and while it's not always healthy, it has its upsides). Ask anyone with chronic pain and they'll tell you that treating pain eventually becomes your hobby, a bottomless well of esoteric dives into various \"modalities\" of pain treatment. Thus it is that I've found myself on one or two psychologists' couches, learning about different mental approaches to living with constant pain. One of the most useful pieces of advice I've gotten was to attend closely to how my pain changes &#8211; how it ebbs and flows. The point is that if pain changes, that means that it can change. It feels eternal, but it comes and goes. Maybe someday it will go altogether. And even if it doesn't, it may improve. It probably will, at least for a while. Things change. Our current crop of cowardly, weak appeasers &#8211; in Congress, in Parliament, in the European Parliament &#8211; have, at various times (and very recently), found their spines. The factions within them that militated for the kind of bold action that might meet this moment have, from time to time, won the day. We have lived through total transformations in our politics before, and that means we might live through them again: https://hypertext.niskanencenter.org/p/the-fragmentation-flywheel Sure, it's easy and tempting to assume that our leaders will always suck as hard as they suck now. But latent in that assumption is that the leaders who presided over big, incredible transformations were exceptional people. Maybe they were and maybe they weren't, but I'm here to tell you, ten minutes' worth of research into the biographies of the \"heroes\" of our history will reveal them to have been every bit as capable of monstrousness, cowardice, cruelty and pig-ignorant bigotry as any of today's rotating cast of fascist goons: https://truthout.org/articles/disrupting-the-myth-of-franklin-d-roosevelt-in-the-age-of-trump-sanders-and-clinton/ The question isn't merely \"How do we elect better leaders?\" It's \"How do we make our leaders follow us?\" Today's Democrats are unserious quislings who keep bringing a squirt-gun to a mass-casualty assault-rifle spree-shooting. How do we terrorize these cowards into rising to the moment? If we want Congressional Democrats to form a Nuremburg Caucus and start holding hearings on who they're going to put in the dock when the Trump regime collapses, we're going to have to drive them to it. And we can! The Democrats who gave us the New Deal weren't braver or more moral than the self-dealing millionaires in Congress today &#8211; they were more afraid of their base. Things change. Some years ago, I gave a speech at Consumer Reports headquarters in Poughkeepsie, trying to get them to refuse to give a passing grade to any product with DRM, on the grounds that the manufacturer could alter how that device worked at any time in the future, meaning that no matter how well a device worked now, it might turn into a pile of shit at any time in the future: https://www.soundguys.com/the-sonos-app-death-spiral-132873/ They didn't take me up on this suggestion, obviously. They made the (seemingly) reasonable point that people bought Consumer Reports to find out what to buy, not to be told that they shouldn't buy anything. Every product in many key categories came with DRM, meaning that their recommendation would have had to be \"just don't buy any of it.\" But today, consumer review sites do sometimes recommend nothing: https://www.mozillafoundation.org/en/blog/privacy-nightmare-on-wheels-every-car-brand-reviewed-by-mozilla-including-ford-volkswagen-and-toyota-flunks-privacy-test/ And of course, there's some precedent here. Somewhere between the emergence of the evidence for seatbelts and the appearance of seatbelts in most makes and models of cars, there would have been a time when the answer to \"which car should I buy?\" was \"don't buy a car, they're all unsafe at any speed.\" Things change. Today, every car has a seatbelt, and they'd continue to do so, even if we did away with regulations requiring seatbelts. Driving a car without a seatbelt would be as weird and terrible as using a radium suppository: https://pluralistic.net/2024/09/19/just-stop-putting-that-up-your-ass/#harm-reduction Things change. The nine-justice Supreme Court isn't an eternal verity. It didn't come down off a mountain on two stone tablets. It's about ten seconds old: https://en.wikipedia.org/wiki/Judiciary_Act_of_1869 Tomorrow, it will be different: https://pluralistic.net/2020/09/20/judicial-equilibria/#pack-the-court Our eternals are all ephemerals. The idea that we should tax capital gains at half the rate of wages? It was practically invented yesterday. You know who thought we should tax all income at the same rate? That noted Bolshevik, Ronald fuckin' Reagan: https://archive.thinkprogress.org/flashback-reagan-raised-capital-gains-taxes-to-the-same-level-as-wage-taxes-for-first-time-444438edf242/ We're living through a time of change. Much of it is calamitous. Some of it wondrous: https://pluralistic.net/2025/06/28/mamdani/#trustbusting It's so easy to slip into the habit of thinking that nothing will change, that our politicians will never fear us more than they love the money and power they get from catering to the Epstein class. I'm not denying that this is how they view the world today, but there was a time in living memory when it wasn't true. If it changed before, it can change again: https://pluralistic.net/2026/01/15/how-the-light-gets-in/#theories-of-change Things change. Hey look at this (permalink) The Scourge of Online Sports Betting https://prospect.org/2026/02/04/feb-2026-magazine-sports-scourge-online-betting-fanduel-draftkings/ ICE has offices in 5 Canadian cities. Here’s what it can — and can’t — do https://www.cbc.ca/lite/story/9.7073273 RIP, Fobazi M Ettarh https://bsky.app/profile/fobettarh.bsky.social/post/3me34k3rtvc2j The Roots of the Youth Sports Gold Rush https://prospect.org/2026/02/05/feb-2026-magazine-youth-sports-private-equity/ Object permanence (permalink) #20yrsago UK nurses want to supply clean blades and cutting advice to self-harmers https://web.archive.org/web/20060206205108/http://www.timesonline.co.uk/article/0,,2087-2025748,00.html #20yrsago PC built into whisky bottle https://web.archive.org/web/20060210043104/https://metku.net/index.html?sect=view&#38;amp;n=1&#38;amp;path=mods/whiskypc/index_eng #15yrsago Startups of London’s “Silicon Roundabout” https://www.theguardian.com/technology/2011/feb/06/tech-startup-internet-entrepreneurs #15yrsago Antifeatures: deliberate, expensive product features that no customer wants https://mako.cc/copyrighteous/antifeatures-at-the-free-technology-academy #15yrsago Steampunk Etch-a-Sketch https://www.reddit.com/r/pics/comments/erbnf/a_steampunk_etchasketch_we_made_for_a_friend_this/ #10yrsago There’s a secret “black site” in New York where terrorism suspects are tortured for years at a time https://web.archive.org/web/20160205143012/https://theintercept.com/2016/02/05/mahdi-hashi-metropolitan-correctional-center-manhattan-guantanamo-pretrial-solitary-confinement/ #10yrsago Error 53: Apple remotely bricks phones to punish customers for getting independent repairs https://www.theguardian.com/money/2016/feb/05/error-53-apple-iphone-software-update-handset-worthless-third-party-repair?CMP=Share_iOSApp_Other #10yrsago Toronto City Council defies mayor, demands open, neutral municipal broadband https://www.michaelgeist.ca/2016/02/toronto-city-council-sides-with-crtc-in-rejecting-mayor-torys-support-of-bell-appeal/ #5yrsago Amazon's brutal warehouse \"megacycle\" https://pluralistic.net/2021/02/05/la-bookseller-royalty/#megacycle #5yrsago AT&#38;T customer complains…via WSJ ad https://pluralistic.net/2021/02/05/la-bookseller-royalty/#go-aaron-go #1yrago MLMs are the mirror-world version of community organizing https://pluralistic.net/2025/02/05/power-of-positive-thinking/#the-socialism-of-fools Upcoming appearances (permalink) Salt Lake City: Enshittification at the Utah Museum of Fine Arts (Tanner Humanities Center), Feb 18 https://tanner.utah.edu/center-events/cory-doctorow/ Montreal (remote): Fedimtl, Feb 24 https://fedimtl.ca/ Victoria: 28th Annual Victoria International Privacy &#38; Security Summit, Mar 3-5 https://www.rebootcommunications.com/event/vipss2026/ Berkeley: Bioneers keynote, Mar 27 https://conference.bioneers.org/ Berlin: Re:publica, May 18-20 https://re-publica.com/de/news/rp26-sprecher-cory-doctorow Berlin: Enshittification at Otherland Books, May 19 https://www.otherland-berlin.de/de/event-details/cory-doctorow.html Hay-on-Wye: HowTheLightGetsIn, May 22-25 https://howthelightgetsin.org/festivals/hay/big-ideas-2 Recent appearances (permalink) How the Internet Got Worse (Masters in Business) https://www.youtube.com/watch?v=auXlkuVhxMo Enshittification (Jon Favreau/Offline): https://crooked.com/podcast/the-enshittification-of-the-internet-with-cory-doctorow/ Why Big Tech is a Trap for Independent Creators (Stripper News) https://www.youtube.com/watch?v=nmYDyz8AMZ0 Enshittification (Creative Nonfiction podcast) https://brendanomeara.com/episode-507-enshittification-author-cory-doctorow-believes-in-a-new-good-internet/ Enshittification with Plutopia https://plutopia.io/cory-doctorow-enshittification/ Latest books (permalink) \"Canny Valley\": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025 \"Enshittification: Why Everything Suddenly Got Worse and What to Do About It,\" Farrar, Straus, Giroux, October 7 2025 https://us.macmillan.com/books/9780374619329/enshittification/ \"Picks and Shovels\": a sequel to \"Red Team Blues,\" about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (https://us.macmillan.com/books/9781250865908/picksandshovels). \"The Bezzle\": a sequel to \"Red Team Blues,\" about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (thebezzle.org). \"The Lost Cause:\" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (http://lost-cause.org). \"The Internet Con\": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (http://seizethemeansofcomputation.org). Signed copies at Book Soup (https://www.booksoup.com/book/9781804291245). \"Red Team Blues\": \"A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before.\" Tor Books http://redteamblues.com. \"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin\", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 https://chokepointcapitalism.com Upcoming books (permalink) \"Unauthorized Bread\": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026 \"Enshittification, Why Everything Suddenly Got Worse and What to Do About It\" (the graphic novel), Firstsecond, 2026 \"The Memex Method,\" Farrar, Straus, Giroux, 2026 \"The Reverse-Centaur's Guide to AI,\" a short book about being a better AI critic, Farrar, Straus and Giroux, June 2026 Colophon (permalink) Today's top sources: Currently writing: \"The Post-American Internet,\" a sequel to \"Enshittification,\" about the better world the rest of us get to have now that Trump has torched America (1005 words today, 22660 total) \"The Reverse Centaur's Guide to AI,\" a short book for Farrar, Straus and Giroux about being an effective AI critic. LEGAL REVIEW AND COPYEDIT COMPLETE. \"The Post-American Internet,\" a short book about internet policy in the age of Trumpism. PLANNING. A Little Brother short story about DIY insulin PLANNING This work &#8211; excluding any serialized fiction &#8211; is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net. https://creativecommons.org/licenses/by/4.0/ Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution. How to get Pluralistic: Blog (no ads, tracking, or data-collection): Pluralistic.net Newsletter (no ads, tracking, or data-collection): https://pluralistic.net/plura-list Mastodon (no ads, tracking, or data-collection): https://mamot.fr/@pluralistic Medium (no ads, paywalled): https://doctorow.medium.com/ Twitter (mass-scale, unrestricted, third-party surveillance and advertising): https://twitter.com/doctorow Tumblr (mass-scale, unrestricted, third-party surveillance and advertising): https://mostlysignssomeportents.tumblr.com/tagged/pluralistic \"When life gives you SARS, you make sarsaparilla\" -Joey \"Accordion Guy\" DeVilla READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies (\"BOGUS AGREEMENTS\") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer. ISSN: 3066-764X",
          "content": "<p><!--\nTags:\ntheories of change, science fiction, inevitabalism,\n\nSummary:\nAll laws are local; Hey look at this; Upcoming appearances; Recent appearances; Latest books; Upcoming books\n\nURL:\nhttps://pluralistic.net/2026/02/05/contingency/\n\nTitle:\nPluralistic: All laws are local (05 Feb 2026) contingency\n\nBullet:\n&#x1f6cc;&#x1f3fb;\n\nSeparator:\n->->->->->->->->->->->->->->->->->->->->->->->->->->->->->->\n\nTop Sources:\nNone\n\n--><br />\n<a href=\"https://pluralistic.net/2026/02/05/contingency/\"><img class=\"xmasthead_link\" src=\"https://i0.wp.com/craphound.com/images/05Feb2026.jpg?w=840&#038;ssl=1\" /></a></p>\n<h1 class=\"toch1\">Today's links</h1>\n<ul class=\"toc\">\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/05/contingency/#this-too-shall-pass\">All laws are local</a>: And no law knows how evitable it is.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/05/contingency/#linkdump\">Hey look at this</a>: Delights to delectate.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/05/contingency/#retro\">Object permanence</a>: Whisky PC; Anitfeatures; Silicon Roundabout; Steampunk Etch-A-Sketch; MLMs as mirror-world organizers.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/05/contingency/#upcoming\">Upcoming appearances</a>: Where to find me.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/05/contingency/#recent\">Recent appearances</a>: Where I've been.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/05/contingency/#latest\">Latest books</a>: You keep readin' em, I'll keep writin' 'em.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/05/contingency/#upcoming-books\">Upcoming books</a>: Like I said, I'll keep writin' 'em.\n</li>\n<li class=\"xToC\"><a href=\"https://pluralistic.net/2026/02/05/contingency/#bragsheet\">Colophon</a>: All the rest.\n</li>\n</ul>\n<p><span id=\"more-12381\"></span></p>\n<hr />\n<p><a name=\"this-too-shall-pass\"></a><br />\n<img alt=\"A pair of broken off statue legs, shod ",
          "depth": 0.6,
          "published": "2026-02-05T12:57:09+00:00",
          "category": "趋势观点"
        }
      ],
      "total_mentions": 1,
      "avg_depth": 0.6,
      "heat_score": 29.0,
      "rank": 11
    },
    {
      "canonical_name": "软件开发职业生涯故事",
      "category": "行业动态",
      "articles": [
        {
          "title": "Stories From 25 Years of Computing",
          "link": "https://susam.net/twenty-five-years-of-computing.html",
          "source": "susam.net",
          "summary": "<p>\n  Last year, I completed 20 years in professional software\n  development.  I wanted to write a post to mark the occasion back\n  then, but couldn't find the time.  This post is my attempt to make\n  up for that omission.  In fact, I have been involved in software\n  development for slightly longer than 20 years.  Although I had\n  my <a href=\"fd-100.html\">first taste of computer programming</a> as\n  a child, it was only when I entered university about 25 years ago\n  that I seriously got into software development.  So I'll start my\n  stories from there.  These stories are less about software and more\n  about people.  Unlike many career anniversary posts, this one\n  contains no grand wisdom or lessons.  Just a collection of stories.\n  I hope you'll enjoy at least a few of them.\n</p>\n<h2 id=\"contents\">Contents<a href=\"#contents\"></a></h2>\n<ul>\n  <li><a href=\"#my-first-lesson-in-html\">My First Lesson in HTML</a></li>\n  <li><a href=\"#reset-vector\">The Reset Vector</a></li>\n  <li><a href=\"#my-first-job\">My First Job</a></li>\n  <li><a href=\"#sphagetti-code\">Sphagetti Code</a></li>\n  <li><a href=\"#animated-television-widgets\">Animated Television Widgets</a></li>\n  <li><a href=\"#good-blessings\">Good Blessings</a></li>\n  <li><a href=\"#the-ctf-scoreboard\">The CTF Scoreboard</a></li>\n</ul>\n<h2 id=\"my-first-lesson-in-html\">My First Lesson in HTML<a href=\"#my-first-lesson-in-html\"></a></h2>\n<p>\n  The first story takes place in 2001, shortly after I joined\n  university.  One evening, I went to the university computer\n  laboratory to browse the web.  Out of curiosity, I typed\n  <code>susam.com</code> into the address bar to see what kind of\n  website existed there.  I ended up on this home page:\n  <a href=\"https://web.archive.org/web/20010721163153/http://susam.com/\">susam.com</a>.\n  It looked much larger back then because display resolutions were\n  lower, so the text and banner covered almost half the screen.  I was\n  simply trying to make sense of the Internet.  I remember wondering\n  what it would take to create my own website, perhaps\n  at <code>susam.com</code>.  That's when an older student who had\n  been watching me browse over my shoulder approached and asked\n  whether that was my name and if I had created the website.  I told\n  him I hadn't and that I had no idea how websites were made.  He\n  asked me to move aside, took my seat and clicked View &gt; Source in\n  Internet Explorer.  He then explained how websites are made of HTML\n  pages and how those pages are simply text instructions.\n</p>\n<p>\n  Next, he opened Notepad and wrote a simple HTML page containing\n  nothing but a <code>&lt;BODY&gt;</code> tag with 'HELLO' inside it,\n  then showed me how it appeared in the browser.  He demonstrated a\n  few more things as well, such as using the <code>&lt;FONT&gt;</code>\n  tag to change colour, typeface and size.  It was only a brief\n  ten-minute tutorial, but it made the World Wide Web feel much less\n  mysterious and far more fascinating.\n</p>\n<p>\n  That person had an ulterior motive though.  After the tutorial, he\n  never gave the seat back to me.  He just continued browsing the Web\n  and waited for me to leave.  I was too timid to ask for my seat\n  back.  Seats were limited, so I returned to my dorm room both\n  disappointed that I couldn't continue browsing that day and excited\n  about all the websites I might create with this newfound knowledge.\n  I could never register <code>susam.com</code> for myself though.\n  That domain was always used by some business selling Turkish\n  cuisines.  Eventually, I managed to get the next best thing:\n  a <code>.net</code> domain of my own.  That brief encounter in the\n  university laboratory set me on a lifelong path of creating and\n  maintaining personal websites.\n</p>\n<h2 id=\"reset-vector\">The Reset Vector<a href=\"#reset-vector\"></a></h2>\n<p>\n  <p>\n  The second story also comes from my university days.  I was hanging\n  out with my mates in the computer laboratory.  In front of me was\n  MS-DOS running on a machine with an Intel 8086 processor.  I think I\n  was working on a lift control program when my mind drifted to a\n  small detail about the 8086 microprocessor that we had recently\n  learnt in a lecture.  Our professor had explained that when the 8086\n  is reset, execution begins with CS:IP set to FFFF:0000.  So I\n  murmured to anyone who cared to listen, 'I wonder if the system will\n  reboot if I jump to FFFF:0000.'  I then opened\n  <code>DEBUG.EXE</code> and jumped to that address.\n</p>\n<pre><samp>C:\\&gt;<kbd>DEBUG</kbd>\n<kbd>G =FFFF:0000</kbd></samp></pre>\n<p>\n  The machine rebooted instantly.  One of my friends, who topped the\n  class every semester, had been watching over my shoulder.  As soon\n  as the machine restarted, he exclaimed, 'How did you do that?'  I\n  explained that the reset vector is located at physical address\n  <code>FFFF0</code>, and that the CS:IP value\n  <code>FFFF:0000</code> maps to that address in real mode.  After\n  that, I went back to working on my lift control program and didn't\n  think much more about the incident.\n</p>\n<p>\n  About a week later, the same friend came to my dorm room.  He sat\n  down with a very serious expression and asked, 'How did you know to\n  do that?  How did it occur to you to jump to the reset vector?'  I\n  must have said something like, 'It just occurred to me.  I\n  remembered that detail from the lecture and wanted to try it out.'\n  He then said, 'I want to be able to think like that.  I come top of\n  the class every year, but I don't think the way you do.  I would\n  never have thought of taking a small detail like that and testing it\n  myself.'  I replied that I was just curious to see whether what we\n  had learnt actually worked in practice.  He responded, 'And that's\n  exactly it.  It would never occur to me to try something like that.\n  I feel disappointed that I keep coming top of the class, yet I am\n  not curious in the same way you are.  I've decided I don't want to\n  top the class anymore.  I just want to explore and experiment with\n  what we learn, the way you do.'\n</p>\n<p>\n  That was all he said before getting up and heading back to his dorm\n  room.  I didn't take it very seriously at the time.  I couldn't\n  imagine why someone would willingly give up the accomplishment of\n  coming first every year.  But I was wrong.  He never topped the\n  class again.  He still ranked highly, often within the top ten, but\n  he kept his promise of never finishing first again.  To this day, I\n  remember the incident fondly.  I still feel a mix of embarrassment\n  and pride at having inspired someone to step back academically in\n  order to have more fun with learning.  Of course, there is no reason\n  one cannot do both.  But in the end, that was his decision, not\n  mine.\n</p>\n<h2 id=\"my-first-job\">My First Job<a href=\"#my-first-job\"></a></h2>\n<p>\n  In my first job, I was assigned to work on the installer for a\n  specific component of an e-banking product.  The installer was\n  written in Python and was quite fragile.  During my first week on\n  the project, I spent much of my time stabilising the installer and\n  writing a user guide with step-by-step instructions on how to use\n  it.  The result was well received and appreciated by both my seniors\n  and management.  To my surprise, my user guide was praised more than\n  my improvements to the installer.  While the first few weeks were\n  enjoyable, I soon realised I would not find the work fulfilling for\n  very long.  I wrote to management a few times to ask whether I could\n  transfer to a team where I could work on something more substantial.\n</p>\n<p>\n  My emails were initially met with resistance.  After several rounds\n  of discussion, however, someone who had heard about my situation\n  reached out and suggested a team whose manager might be interested\n  in interviewing me.  The team was based in a different city.  I was\n  young and willing to relocate wherever I could find good work, so I\n  immediately agreed to the interview.\n</p>\n<p>\n  This was in 2006, when video conferencing was not yet common.  On\n  the day of the interview, the hiring manager called me on my desk\n  phone.  He began by introducing the team, which called itself\n  <em>Archie</em>, short for <em>architecture</em>.  The team developed\n  and maintained the web framework and core architectural components\n  on which the entire e-banking product was built.  The product had\n  existed long before open source frameworks such as Spring or Django\n  became popular, so features such as API routing, authentication and\n  authorisation layers, cookie management and similar capabilities were\n  all implemented in-house by this specialised team.  Because the\n  software was used in banking environments, it also had to pass strict\n  security testing and audits to minimise the risk of serious flaws.\n</p>\n<p>\n  The interview began well.  He asked several questions related to\n  software security, such as what SQL injection is and how it can be\n  prevented or how one might design a web framework that mitigates\n  cross-site scripting attacks.  He also asked programming questions,\n  most of which I answered pretty well.  Towards the end, however, he\n  asked how we could prevent MITM attacks.  I had never heard the\n  term, so I admitted that I did not know what MITM meant.  He then\n  asked, 'Man in the middle?' but I still had no idea what that meant\n  or whether it was even a software engineering concept.  He replied,\n  'Learn everything you can about PKI and MITM.  We need to build a\n  digital signatures feature for one of our corporate banking\n  products.  That's the first thing we'll work on.'\n</p>\n<p>\n  Over the next few weeks, I studied RFCs and documentation related to\n  public key infrastructure, public key cryptography standards and\n  related topics.  At first, the material felt intimidating, but after\n  spending time each evening reading whatever relevant literature I\n  could find, things gradually began to make sense.  Concepts that\n  initially seemed complex and overwhelming eventually felt intuitive\n  and elegant.  I relocated to the new city a few weeks later and\n  delivered the digital signatures feature about a month after joining\n  the team.  We used the open source Bouncy Castle library to\n  implement digital signatures, which became my first real interaction\n  with the open source community.  After that I worked on other parts\n  of the product too.  The most rewarding part was knowing that the\n  code I was writing became part of a mature product used by hundreds\n  of banks and millions of users.  It was especially satisfying to see\n  the work pass security testing and audits and be considered ready\n  for release.\n</p>\n<p>\n  That was my first real engineering job.  My manager also turned out\n  to be an excellent mentor.  Working with him helped me develop new\n  skills and his encouragement gave me confidence that stayed with me\n  for years.  Nearly two decades have passed since then, yet the\n  product apparently still exists.  In fact, in my current phase of\n  life I sometimes happen to use that product as a customer.\n  Sometimes, I open the browser developer tools to view the page\n  source and can still see traces of the HTML generated by code I\n  wrote almost twenty years ago.\n</p>\n<h2 id=\"sphagetti-code\">Sphagetti Code<a href=\"#sphagetti-code\"></a></h2>\n<p>\n  Around 2007 or 2008, I began working on a proof of concept for\n  developing widgets for an OpenTV set-top box.  The work involved\n  writing code in a heavily trimmed-down version of C.  One afternoon,\n  while making good progress on a few widgets, I noticed that they\n  would occasionally crash at random.  I tried tracking down the bugs,\n  but I was finding it surprisingly difficult to understand my own\n  code.  I had managed to produce some truly spaghetti-like code,\n  complete with dubious pointer operations that were almost certainly\n  responsible for the crashes, yet I could not pinpoint where exactly\n  things were going wrong.\n</p>\n<p>\n  Ours was a small team of four people, each working on an independent\n  proof of concept.  The most senior person on the team acted as our\n  lead and architect.  Later that afternoon, I showed him my progress\n  and explained that I was still trying to hunt down the bugs causing\n  the widgets to crash.  He asked whether he could look at the code.\n  After going through it briefly and probably realising that it was a\n  bit of a mess, he asked me to send him the code as a tarball, which\n  I promptly did.\n</p>\n<p>\n  He then went back to his desk to study the code.  I remember\n  thinking, 'There is no way he is going to find the problem.  I have\n  been debugging this for hours and even I barely understand what I\n  have written.  This is the worst spaghetti code I have ever\n  produced.'  With little hope of a quick solution, I went back to\n  debugging on my own.\n</p>\n<p>\n  Barely five minutes later, he came back to my desk and asked me to\n  open a specific file.  He then showed me exactly where the pointer\n  bug was.  It had taken him only a few minutes not only to read my\n  tangled code but also to understand it well enough to identify the\n  fault and point it out.  As soon as I fixed that line, the crashes\n  disappeared.  I was genuinely in awe of his skill.\n</p>\n<p>\n  I have always loved computing and programming, so I had assumed I\n  was already fairly good at it.  That incident, however, made me\n  realise how much further I still had to go before I could consider\n  myself a good software developer.  I did improve significantly in\n  the years that followed and today I am far better at managing\n  software complexity than I was back then.\n</p>\n<h2 id=\"animated-television-widgets\">Animated Television Widgets<a href=\"#animated-television-widgets\"></a></h2>\n<p>\n  In another project from that period, we worked on another set-top\n  box platform that supported Java Micro Edition (Java ME) for widget\n  development.  One day, the same architect from the previous story\n  asked whether I could add animations to the widgets.  I told him\n  that it should be possible.  To make this story clearer, though, I\n  need to explain how the different stakeholders in the project were\n  organised.\n</p>\n<p>\n  Our small team effectively played the role of the software vendor.\n  The final product going to market would carry the brand of a major\n  telecom carrier, offering direct-to-home (DTH) television services,\n  with the set-top box being one of the products sold to customers.\n  The set top box was manufactured by another company.  So the project\n  was a partnership between three parties: our company as the software\n  vendor, the telecom carrier and the set-top box manufacturer.  The\n  telecom carrier wanted to know whether widgets could be animated on\n  screen with smooth slide-in and slide-out effects.  That was why the\n  architect approached me to ask whether it could be done, and I told\n  him it should be possible.\n</p>\n<p>\n  I then began working on animating the widgets.  Meanwhile, the\n  architect and a few senior colleagues attended a business meeting with\n  all the partners present.  During the meeting, he explained that we\n  were evaluating whether widget animations could be supported.  The\n  set-top box manufacturer immediately dismissed the idea, saying,\n  'That's impossible.  Our set-top box does not support animation.'\n  When the architect returned and shared this with us, I replied, 'I do\n  not understand.  If I can draw a widget, I can animate it too.  All\n  it takes is clearing the widget and redrawing it at slightly different\n  positions repeatedly.  In fact, I already have a working version.'\n  I then showed a demo of the animated widgets running on the emulator.\n</p>\n<p>\n  The following week, the architect attended another partners' meeting\n  where he shared updates about our animated widgets.  I was not\n  personally present, so what follows is second-hand information\n  passed on by those who were there.  I learnt that the set-top box\n  company reacted angrily.  For some reason, they were unhappy that we\n  had managed to achieve results using their set-top box and APIs that\n  they had officially described as impossible.  They demanded that we\n  stop work on animation immediately, arguing that our work could not\n  be allowed to contradict their official position.  If I remember\n  correctly, there were even suggestions of legal consequences.  At\n  that point, the telecom carrier's representative intervened and\n  bluntly told the set-top box representative to just shut up.  If the\n  set top box guy was furious, the telecom guy was even more so, 'You\n  guys told us animation was not possible and these people are showing\n  that it is.  You manufacture the set-top box.  How can you not know\n  what it is capable of?'\n</p>\n<p>\n  Meanwhile, I continued working and completed my proof-of-concept\n  implementation.  It worked very well in the emulator, but I did not\n  yet have access to the actual hardware.  The device was still in the\n  process of being shipped to us, so all my early proof-of-concepts\n  ran on the emulator.  The following week, the architect planned to\n  travel to the set-top box company's office to test my widgets on the\n  real hardware.\n</p>\n<p>\n  At the time, I was quite proud of having apparently proven the\n  manufacturer wrong.  Here I was, an engineer in his twenties working\n  on one of my first major projects, already demonstrating\n  capabilities that even the hardware maker believed were impossible.\n  But when the architect travelled to test the widgets on the actual\n  device, a problem emerged.  What looked like buttery smooth\n  animation on the emulator appeared noticeably choppy on a real\n  television.  Over the next few weeks, I experimented with frame\n  rates, buffering strategies and optimising the computation done in\n  the the rendering loop.  Each week, the architect travelled for\n  testing and returned with the same report: the animation was still\n  choppy.  The modest embedded hardware could not keep up with the\n  required computation and rendering.  In the end, the telecom carrier\n  decided that no animation was better than poor animation and dropped\n  the idea altogether.  So in the end, the set-top box developers\n  turned out to be correct after all.\n</p>\n<h2 id=\"good-blessings\">Good Blessings<a href=\"#good-blessings\"></a></h2>\n<p>\n  Back in 2009, after completing about a year at RSA Security, I began\n  looking for work that felt more intellectually stimulating,\n  especially projects involving mathematics and algorithms.  I spoke\n  with a few senior leaders about this, but nothing materialised for\n  some time.  Then one day, Dr Burt Kaliski, Chief Scientist at RSA\n  Laboratories, asked to meet me to discuss my career aspirations.  I\n  have written about this in more detail in another post here:\n  <a href=\"good-blessings.html\">Good Blessings</a>.  I will summarise\n  what followed.\n</p>\n<p>\n  Dr Kaliski met me and offered a few suggestions about the kinds of\n  teams I might approach to find more interesting work.  I followed\n  his advice and eventually joined a team that turned out to be an\n  excellent fit.  I remained with that team for the next six years.\n  During that time, I worked on parser generators, formal language\n  specification and implementation, as well as indexing and querying\n  components of a petabyte-scale database.  I learnt something new\n  almost every day during those six years, and it remains one of the\n  most enjoyable periods of my career.  I have especially fond\n  memories of working on parser generators alongside remarkably\n  skilled engineers from whom I learnt a lot.\n</p>\n<p>\n  Years later, I reflected on how that brief meeting with Dr Kaliski\n  had altered the trajectory of my career.  I realised I was not sure\n  whether I had properly expressed my gratitude to him for the role he\n  had played in shaping my path.  So I wrote to thank him and explain\n  how much that single conversation had influenced my life.  A few\n  days later, Dr Kaliski replied, saying he was glad to know that the\n  steps I took afterwards had worked out well.  Before ending his\n  message, he wrote this heart-warming note:\n</p>\n<blockquote>\n  &lsquo;One of my goals is to be able to provide encouragement to\n  others who are developing their careers, just as others have\n  invested in mine, passing good blessings from one generation to\n  another.&rsquo;\n</blockquote>\n<h2 id=\"the-ctf-scoreboard\">The CTF Scoreboard<a href=\"#the-ctf-scoreboard\"></a></h2>\n<p>\n  This story comes from 2019.  By then, I was no longer a\n  twenty-something engineer just starting out.  I was now a\n  middle-aged staff engineer with years of experience building both\n  low-level networking systems and database systems.  Most of my work\n  up to that point had been in C and C++.  I was now entering a new\n  phase where I would be developing microservices professionally in\n  languages such as Go and Python.  None of this was unfamiliar\n  territory.  Like many people in this profession, computing has long\n  been one of my favourite hobbies.  So although my professional work\n  for the previous decade had focused on C and C++, I had plenty of\n  hobby projects in other languages, including Python and Go.  I\n  cannot even say that I missed working in C and C++.  After all, who\n  wants to spend their days chasing memory bugs in core dumps when you\n  could be building features and delivering real value to customers?\n</p>\n<p>\n  In October 2019, during Cybersecurity Awareness Month, a Capture the\n  Flag (CTF) event was organised at our office.  The contest featured\n  all kinds of puzzles, ranging from SQL injection challenges to\n  insecure cryptography problems.  Some challenges also involved\n  reversing binaries and exploiting stack overflow vulnerabilities.\n</p>\n<p>\n  I am usually rather intimidated by such contests.  The whole idea of\n  competitive problem-solving under time pressure tends to make me\n  nervous.  But one of my colleagues persuaded me to participate in\n  the CTF.  And, somewhat to my surprise, I turned out to be rather\n  good at it.  Within about eight hours, I had solved roughly 90% of\n  the puzzles.  I finished at the top of the scoreboard.\n</p>\n<figure>\n  <img alt=\"Scoreboard of a Capture the Flag (CTF) event\" src=\"files/blog/ctf-2019.png\" />\n  <figcaption>\n    CTF Scoreboard\n  </figcaption>\n</figure>\n<p>\n  In my younger days, I was generally known to be a good problem\n  solver.  I was often consulted when thorny problems needed solving\n  and I usually managed to deliver results.  I also enjoyed solving\n  puzzles.  I had a knack for them and happily spent hours, sometimes\n  days, working through obscure mathematical or technical puzzles and\n  sharing detailed write-ups with friends of the nerd variety.  So\n  tackling arcane and seemingly pointless puzzles was very much my\n  thing.  Seen in that light, my performance at the CTF probably\n  should not have surprised me.  Still, I was very pleased.  It was\n  reassuring to know that I could still rely on my systems programming\n  experience to solve obscure challenges.\n</p>\n<p>\n  During the course of the contest, my performance became something of\n  a talking point in the office.  Colleagues occasionally stopped by\n  my desk to appreciate how well I was doing in the CTF.  Two much\n  younger colleagues, both engineers I admired for their skill and\n  professionalism, were discussing the results nearby.  They were\n  speaking softly, but I could still overhear parts of their\n  conversation.  Curious, I leaned slightly and listened a bit more\n  carefully.  I wanted to know what these two people, whom I admired a\n  great deal, thought about my performance.\n</p>\n<p>\n  One of them remarked on how well I was doing in the contest.  The\n  other replied, 'Of course he is doing well.  He has more than ten\n  years of experience in C.'  At that moment, I realised that no\n  matter how well I solved those puzzles, the result would naturally\n  be credited to experience.  In my younger days, when I solved tricky\n  problems, people would sometimes call me smart.  Now it was\n  expected.  Not that I particularly care for such labels anyway, but\n  it did make me realise how things had changed.  I was now simply the\n  person with many years of experience, and solving challenges that\n  involved dissecting binaries and solving technical puzzles was\n  expected rather than remarkable.\n</p>\n<p>\n  I continue to sharpen my technical skills to this day.  While my\n  technical results may now simply be attributed to experience, I hope\n  I can continue to make a good impression through my professionalism,\n  ethics and kindness towards the people I work with.  If those leave\n  a lasting impression, that is good enough for me.\n</p>\n<!-- ### -->\n<p>\n  <a href=\"https://susam.net/twenty-five-years-of-computing.html\">Read on website</a> |\n  <a href=\"https://susam.net/tag/technology.html\">#technology</a> |\n  <a href=\"https://susam.net/tag/programming.html\">#programming</a>\n</p>",
          "content": "<p>\n  Last year, I completed 20 years in professional software\n  development.  I wanted to write a post to mark the occasion back\n  then, but couldn't find the time.  This post is my attempt to make\n  up for that omission.  In fact, I have been involved in software\n  development for slightly longer than 20 years.  Although I had\n  my <a href=\"fd-100.html\">first taste of computer programming</a> as\n  a child, it was only when I entered university about 25 years ago\n  that I seriously got into software development.  So I'll start my\n  stories from there.  These stories are less about software and more\n  about people.  Unlike many career anniversary posts, this one\n  contains no grand wisdom or lessons.  Just a collection of stories.\n  I hope you'll enjoy at least a few of them.\n</p>\n<h2 id=\"contents\">Contents<a href=\"#contents\"></a></h2>\n<ul>\n  <li><a href=\"#my-first-lesson-in-html\">My First Lesson in HTML</a></li>\n  <li><a href=\"#reset-vector\">The Reset Vector</a></li>\n  <li><a href=\"#my-first-job\">My First Job</a></li>\n  <li><a href=\"#sphagetti-code\">Sphagetti Code</a></li>\n  <li><a href=\"#animated-television-widgets\">Animated Television Widgets</a></li>\n  <li><a href=\"#good-blessings\">Good Blessings</a></li>\n  <li><a href=\"#the-ctf-scoreboard\">The CTF Scoreboard</a></li>\n</ul>\n<h2 id=\"my-first-lesson-in-html\">My First Lesson in HTML<a href=\"#my-first-lesson-in-html\"></a></h2>\n<p>\n  The first story takes place in 2001, shortly after I joined\n  university.  One evening, I went to the university computer\n  laboratory to browse the web.  Out of curiosity, I typed\n  <code>susam.com</code> into the address bar to see what kind of\n  website existed there.  I ended up on this home page:\n  <a href=\"https://web.archive.org/web/20010721163153/http://susam.com/\">susam.com</a>.\n  It looked much larger back then because display resolutions were\n  lower, so the text and banner covered almost half the screen.  I was\n  simply trying to make sense of the Internet.  I remember wonder",
          "depth": 0.5,
          "published": "2026-02-06T00:00:00+00:00",
          "category": "实战技巧"
        }
      ],
      "total_mentions": 1,
      "avg_depth": 0.5,
      "heat_score": 26.0,
      "rank": 12
    }
  ]
}